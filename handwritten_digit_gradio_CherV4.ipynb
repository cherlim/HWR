{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handwritten digit gradio CherV4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUJJPSr+LkUL63MP9i3uc0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cherlim/HWR/blob/main/handwritten_digit_gradio_CherV4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFgGFXlX7SZ3"
      },
      "source": [
        "# Assignment: Handwriting digit recognition\n",
        "**Name: Lim Cher Eng**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZWm0_J9666D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1955e99e-9d80-4c1c-d61e-344cf391963f"
      },
      "source": [
        "!pip install -q gradio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4 MB 11.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 39.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 206 kB 66.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 961 kB 53.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 60.5 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iiHThMh7IjB"
      },
      "source": [
        "import cv2\n",
        "import gradio as gr"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixQA_P4t7GSj",
        "outputId": "7dd3cf12-0734-4ad2-91e7-4471f9910aac"
      },
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0, \n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz_SZHa37gOF",
        "outputId": "6f8e0cd9-f285-4e47-a31a-b15434beef3c"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2740 - accuracy: 0.9218\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1240 - accuracy: 0.9635\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0879 - accuracy: 0.9736\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0673 - accuracy: 0.9790\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0520 - accuracy: 0.9844\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0423 - accuracy: 0.9868\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0340 - accuracy: 0.9892\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0280 - accuracy: 0.9913\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0232 - accuracy: 0.9931\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0198 - accuracy: 0.9940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8140ea7e10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEZupZ499GGO",
        "outputId": "4bda7680-13eb-48d2-b50e-2135c160a9c4"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 893us/step - loss: 0.0895 - accuracy: 0.9758\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08951474726200104, 0.9757999777793884]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1NqbBIh9OV3"
      },
      "source": [
        "model_name = 'digits_recognition_dnn.h5'\n",
        "#model.save(model_name, save_format='h5')\n",
        "model_dnn = tf.keras.models.load_model(model_name)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t1YYEtF7KR3"
      },
      "source": [
        "model_name = 'digits_recognition_cnn.h5'\n",
        "model_cnn = tf.keras.models.load_model(model_name)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjq3qAQ87X0o"
      },
      "source": [
        "# Center input image, fill up broken line, round off edges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvW0zMhs-aV3"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "#urllib.request.urlretrieve('https://github.com/cherlim/NP/blob/main/digits_recognition_cnn.h5', 'cnn.h5')\n",
        "#MODEL_PATH = './cnn.h5'\n",
        "#urllib.request.urlretrieve('https://github.com/cherlim/NP/blob/main/digits_recognition_dnn.h5', 'dnn.h5')\n",
        "#MODEL_PATH = './dnn.h5'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiPe9pIRONYC"
      },
      "source": [
        "# Using moments to center image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAN_ETpuSV_Z"
      },
      "source": [
        "def center_image(image):\n",
        "    height, width = image.shape\n",
        "  \n",
        "    print(image.shape)\n",
        "    wi=(width/2)\n",
        "    he=(height/2)\n",
        "    print(wi,he)\n",
        "\n",
        "# get contours (presumably just one around the nonzero pixels) \n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "# Dilate: morph input image with kernel to fill in the gaps\n",
        "    img_dilate=cv2.dilate(image,kernel,iterations = 1)\n",
        "# Erode the edges to reduce thickness\n",
        "    img_erode=cv2.erode(img_dilate,kernel,iterations = 1)\n",
        "# Set pixel intensity less than input threshold (=95) to 0 \n",
        "# CV2 threshold fn returns 2 outputs: ret=threshold; thresh = thresholded image\n",
        "    ret,thresh = cv2.threshold(img_erode,95,255,0) \n",
        "\n",
        "    M = cv2.moments(thresh)\n",
        "\n",
        "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "\n",
        "    offsetX = (wi-cX)\n",
        "    offsetY = (he-cY)\n",
        "    T = np.float32([[1, 0, offsetX], [0, 1, offsetY]]) \n",
        "    centered_image = cv2.warpAffine(img_erode, T, (width, height))\n",
        "\n",
        "    return centered_image"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoIjb2SDTQQ6"
      },
      "source": [
        "def modelC(image):\n",
        "    image_c = center_image(image)\n",
        "    image_new = image_c.reshape(1, 28, 28, 1) # CNN model input layer shape\n",
        "    #print(\"after reshape 1,28,28,1 \", image_new.shape)\n",
        "    prediction_cnn = model_cnn.predict(image_new).tolist()[0]\n",
        "    return {str(i): prediction_cnn[i] for i in range(10)}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4sNhkD1E3wJ"
      },
      "source": [
        "def modelD(image):\n",
        "    image_c = center_image(image)\n",
        "    image_new = image_c.reshape(1, 28, 28, 1) # DNN model input layer shape\n",
        "    #print(\"after reshape 1,28,28,1 \", image_new.shape)\n",
        "    prediction_dnn = model_dnn.predict(image_new).tolist()[0]\n",
        "    return {str(i): prediction_dnn[i] for i in range(10)}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "25EN73urTrw3",
        "outputId": "123cbc9f-57c1-4a01-dabc-7e50f4cae0f1"
      },
      "source": [
        "label = gr.outputs.Label(num_top_classes = 3) # initializing the output component\n",
        "# launching the interface\n",
        "gr.Interface([modelC, modelD], inputs = \"sketchpad\",outputs = label).launch()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "This share link will expire in 72 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted\n",
            "Running on External URL: https://58826.gradio.app\n",
            "Interface loading below...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://58826.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f8140daab10>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://58826.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbxQqrNnOCV7"
      },
      "source": [
        "# Using bounding box to center image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDJY-jl0OgLN"
      },
      "source": [
        "def center_imageB(image):\n",
        "    height, width = image.shape\n",
        "  \n",
        "    print(image.shape)\n",
        "    wi=(width/2)\n",
        "    he=(height/2)\n",
        "    print(wi,he)\n",
        "\n",
        "# get contours (presumably just one around the nonzero pixels) \n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "# Dilate: morph input image with kernel to fill in the gaps\n",
        "    img_dilate=cv2.dilate(image,kernel,iterations = 1)\n",
        "# Erode the edges to reduce thickness\n",
        "    img_erode=cv2.erode(img_dilate,kernel,iterations = 1)\n",
        "\n",
        "    contours = cv2.findContours(img_erode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    for cntr in contours:\n",
        "        x,y,w,h = cv2.boundingRect(cntr)\n",
        "    \n",
        "    # recenter image\n",
        "    startx = (width - w)//2\n",
        "    starty = (height - h)//2\n",
        "    result = np.zeros_like(image)\n",
        "    result[starty:starty+h,startx:startx+w] = image[y:y+h,x:x+w]\n",
        "\n",
        "    return result"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9yiMrlGO8Jx"
      },
      "source": [
        "def modelBC(image):\n",
        "    image_c = center_imageB(image)\n",
        "    image_new = image_c.reshape(1, 28, 28, 1) # CNN model input layer shape\n",
        "    #print(\"after reshape 1,28,28,1 \", image_new.shape)\n",
        "    prediction_cnn = model_cnn.predict(image_new).tolist()[0]\n",
        "    return {str(i): prediction_cnn[i] for i in range(10)}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guPmI8YrPGHr"
      },
      "source": [
        "def modelBD(image):\n",
        "    image_c = center_imageB(image)\n",
        "    image_new = image_c.reshape(1, 28, 28, 1) # DNN model input layer shape\n",
        "    #print(\"after reshape 1,28,28,1 \", image_new.shape)\n",
        "    prediction_dnn = model_dnn.predict(image_new).tolist()[0]\n",
        "    return {str(i): prediction_dnn[i] for i in range(10)}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "lE8CZTdHPMfz",
        "outputId": "f818ba73-6226-4c10-d699-1ef1ba9335dc"
      },
      "source": [
        "label = gr.outputs.Label(num_top_classes = 3) # initializing the output component\n",
        "# launching the interface\n",
        "gr.Interface([modelBC,modelBD], inputs = \"sketchpad\",outputs = label).launch()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "This share link will expire in 72 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted\n",
            "Running on External URL: https://33681.gradio.app\n",
            "Interface loading below...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://33681.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f8140daa110>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://33681.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YII8Un-WZFnG"
      },
      "source": [
        "# Combining both contour and moments to center the image\n",
        "\n",
        "**\"A Simple and Effective Optical Character Recognition System for Digits Recognition using the Pixel-Contour Features and Mathematical Parameters\"** \n",
        "\n",
        "Ref: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.660.1825&rep=rep1&type=pdf "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCL-FgqjZBGk"
      },
      "source": [
        "def center_imageBM(image):\n",
        "    height, width = image.shape\n",
        "  \n",
        "    print(image.shape)\n",
        "    wi=(width/2)\n",
        "    he=(height/2)\n",
        "    print(wi,he)\n",
        "\n",
        "# get contours (presumably just one around the nonzero pixels) \n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "# Dilate: morph input image with kernel to fill in the gaps\n",
        "    img_dilate=cv2.dilate(image,kernel,iterations = 1)\n",
        "# Erode the edges to reduce thickness\n",
        "    img_erode=cv2.erode(img_dilate,kernel,iterations = 1)\n",
        "\n",
        "    contours = cv2.findContours(img_erode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    for cntr in contours:\n",
        "        x,y,w,h = cv2.boundingRect(cntr)\n",
        "    \n",
        "    # recenter image\n",
        "    startx = (width - w)//2\n",
        "    starty = (height - h)//2\n",
        "    result = np.zeros_like(image)\n",
        "    result[starty:starty+h,startx:startx+w] = image[y:y+h,x:x+w]\n",
        "\n",
        "    # CV2 threshold fn returns 2 outputs: ret=threshold; thresh = thresholded image\n",
        "    #ret,thresh = cv2.threshold(img_erode,95,255,0) \n",
        "\n",
        "    M = cv2.moments(result)\n",
        "\n",
        "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "\n",
        "    offsetX = (wi-cX)\n",
        "    offsetY = (he-cY)\n",
        "    T = np.float32([[1, 0, offsetX], [0, 1, offsetY]]) \n",
        "    centered_image = cv2.warpAffine(result, T, (width, height))\n",
        "\n",
        "\n",
        "\n",
        "    return centered_image"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS8WXSHIbGe3"
      },
      "source": [
        "def modelBMC(image):\n",
        "    image_c = center_imageBM(image)\n",
        "    image_new = image_c.reshape(1, 28, 28, 1) # CNN model input layer shape\n",
        "    #print(\"after reshape 1,28,28,1 \", image_new.shape)\n",
        "    prediction_cnn = model_cnn.predict(image_new).tolist()[0]\n",
        "    return {str(i): prediction_cnn[i] for i in range(10)}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pwtJQOTbKUH"
      },
      "source": [
        "def modelBMD(image):\n",
        "    image_c = center_imageBM(image)\n",
        "    image_new = image_c.reshape(1, 28, 28, 1) # DNN model input layer shape\n",
        "    #print(\"after reshape 1,28,28,1 \", image_new.shape)\n",
        "    prediction_dnn = model_dnn.predict(image_new).tolist()[0]\n",
        "    return {str(i): prediction_dnn[i] for i in range(10)}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "bSHTNB1HbR07",
        "outputId": "75626eab-7271-451f-c8c2-aaa9b58ee2ed"
      },
      "source": [
        "label = gr.outputs.Label(num_top_classes = 3) # initializing the output component\n",
        "# launching the interface\n",
        "gr.Interface([modelBMC,modelBMD], inputs = \"sketchpad\",outputs = label).launch()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "This share link will expire in 72 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted\n",
            "Running on External URL: https://23790.gradio.app\n",
            "Interface loading below...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://23790.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f813f4fd690>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7862/',\n",
              " 'https://23790.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}